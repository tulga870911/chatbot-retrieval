I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 980 Ti
major: 5 minor: 2 memoryClockRate (GHz) 1.228
pciBusID 0000:01:00.0
Total memory: 6.00GiB
Free memory: 5.88GiB
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GeForce GTX 980 Ti
major: 5 minor: 2 memoryClockRate (GHz) 1.228
pciBusID 0000:02:00.0
Total memory: 6.00GiB
Free memory: 5.88GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980 Ti, pci bus id: 0000:02:00.0)
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 5.88G (6312669184 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 4991 get requests, put_count=3301 evicted_count=1000 eviction_rate=0.302939 and unsatisfied allocation rate=0.559006
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 5233 get requests, put_count=4462 evicted_count=2000 eviction_rate=0.448229 and unsatisfied allocation rate=0.532008
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 146 to 160
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 526 get requests, put_count=2545 evicted_count=2000 eviction_rate=0.785855 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 266 get requests, put_count=1294 evicted_count=1000 eviction_rate=0.772798 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 266 get requests, put_count=1306 evicted_count=1000 eviction_rate=0.765697 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 5413 get requests, put_count=5337 evicted_count=2000 eviction_rate=0.374742 and unsatisfied allocation rate=0.394421
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 655 to 720
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 288 get requests, put_count=1393 evicted_count=1000 eviction_rate=0.717875 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 16350 get requests, put_count=16569 evicted_count=1000 eviction_rate=0.0603537 and unsatisfied allocation rate=0.0615291
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 2478 to 2725

Parameters:
BATCH_SIZE=256
DATA_DIR=./data
EMBEDDING_DIM=300
LEARNING_RATE=0.001
LEARNING_RATE_DECAY_EVERY=3000
LEARNING_RATE_DECAY_RATE=0.1
MAX_CONTENT_LENGTH=80
MAX_UTTERANCE_LENGTH=40
NUM_STEPS=1000000
OPTIMIZER=Adam
RNN_DIM=256

Loading data...NO.2
Total words: 79708
Step #99, avg. train loss: 1.90188
Step #199, avg. train loss: 0.73031
Step #299, avg. train loss: 0.69660
Step #399, avg. train loss: 0.67514
Step #499, avg. train loss: 0.66699
Step #599, avg. train loss: 0.65477
Step #699, avg. train loss: 0.64414
Step #799, avg. train loss: 0.63707
Step #899, avg. train loss: 0.63340
Recall @ (1, 10): 0.30409
Recall @ (2, 10): 0.467587
Recall @ (5, 10): 0.766258
Recall @ (10, 10): 1
Step #999, avg. train loss: 0.62015
Step #1099, avg. train loss: 0.61993
Step #1199, avg. train loss: 0.60717
Step #1299, avg. train loss: 0.60632
Step #1399, avg. train loss: 0.59541
Step #1499, avg. train loss: 0.59731
Step #1599, avg. train loss: 0.59154
Step #1699, avg. train loss: 0.58916
Step #1799, avg. train loss: 0.58538
Step #1899, avg. train loss: 0.58319
Recall @ (1, 10): 0.371728
Recall @ (2, 10): 0.533742
Recall @ (5, 10): 0.808384
Recall @ (10, 10): 1
Step #1999, avg. train loss: 0.58101
Step #2099, avg. train loss: 0.57710
Step #2199, avg. train loss: 0.57338
Step #2299, avg. train loss: 0.57348
Step #2399, avg. train loss: 0.57235
Step #2499, avg. train loss: 0.57053
Step #2599, avg. train loss: 0.56558
Step #2699, avg. train loss: 0.55950
Step #2799, avg. train loss: 0.55755
Step #2899, avg. train loss: 0.56228
Recall @ (1, 10): 0.403732
Recall @ (2, 10): 0.566871
Recall @ (5, 10): 0.832413
Recall @ (10, 10): 1
Step #2999, avg. train loss: 0.55718
Step #3099, avg. train loss: 0.54735
Step #3199, avg. train loss: 0.54644
Step #3299, avg. train loss: 0.54922
Step #3399, avg. train loss: 0.55390
Step #3499, avg. train loss: 0.54150
Step #3599, avg. train loss: 0.54057
Step #3699, avg. train loss: 0.54527
Step #3799, avg. train loss: 0.54290
Step #3899, avg. train loss: 0.53881
Recall @ (1, 10): 0.422648
Recall @ (2, 10): 0.58456
Recall @ (5, 10): 0.845552
Recall @ (10, 10): 1
Step #4000, epoch #1, avg. train loss: 0.49510
Step #4100, epoch #1, avg. train loss: 0.48875
Step #4200, epoch #1, avg. train loss: 0.48698
Step #4300, epoch #1, avg. train loss: 0.49076
Step #4400, epoch #1, avg. train loss: 0.48678
Step #4500, epoch #1, avg. train loss: 0.49256
Step #4600, epoch #1, avg. train loss: 0.48617
Step #4700, epoch #1, avg. train loss: 0.49255
Step #4800, epoch #1, avg. train loss: 0.48673
Step #4900, epoch #1, avg. train loss: 0.48464
Recall @ (1, 10): 0.428067
Recall @ (2, 10): 0.590798
Recall @ (5, 10): 0.846268
Recall @ (10, 10): 1
Step #5000, epoch #1, avg. train loss: 0.48838
Step #5100, epoch #1, avg. train loss: 0.48103
Step #5200, epoch #1, avg. train loss: 0.49550
Step #5300, epoch #1, avg. train loss: 0.48850
Step #5400, epoch #1, avg. train loss: 0.48532
Step #5500, epoch #1, avg. train loss: 0.48732
Step #5600, epoch #1, avg. train loss: 0.48136
Step #5700, epoch #1, avg. train loss: 0.48457
Step #5800, epoch #1, avg. train loss: 0.48748
Step #5900, epoch #1, avg. train loss: 0.48348
Recall @ (1, 10): 0.430777
Recall @ (2, 10): 0.595041
Recall @ (5, 10): 0.849284
Recall @ (10, 10): 1
Step #6000, epoch #1, avg. train loss: 0.48234
Step #6100, epoch #1, avg. train loss: 0.47855
Step #6200, epoch #1, avg. train loss: 0.48559
Step #6300, epoch #1, avg. train loss: 0.47850
Step #6400, epoch #1, avg. train loss: 0.48037
Step #6500, epoch #1, avg. train loss: 0.48080
Step #6600, epoch #1, avg. train loss: 0.48014
Step #6700, epoch #1, avg. train loss: 0.48184
Step #6800, epoch #1, avg. train loss: 0.48167
Step #6900, epoch #1, avg. train loss: 0.47813
Recall @ (1, 10): 0.43318
Recall @ (2, 10): 0.596319
Recall @ (5, 10): 0.849744
Recall @ (10, 10): 1
Step #7000, epoch #1, avg. train loss: 0.48169
Step #7100, epoch #1, avg. train loss: 0.48004
Step #7200, epoch #1, avg. train loss: 0.48358
Step #7300, epoch #1, avg. train loss: 0.47779
Step #7400, epoch #1, avg. train loss: 0.48168
Step #7500, epoch #1, avg. train loss: 0.48132
Step #7600, epoch #1, avg. train loss: 0.48019
Step #7700, epoch #1, avg. train loss: 0.47942
Step #7800, epoch #1, avg. train loss: 0.48295
Step #7900, epoch #2, avg. train loss: 0.46586
Recall @ (1, 10): 0.434458
Recall @ (2, 10): 0.59683
Recall @ (5, 10): 0.85046
Recall @ (10, 10): 1
Step #8000, epoch #2, avg. train loss: 0.46834
Step #8100, epoch #2, avg. train loss: 0.46743
Step #8200, epoch #2, avg. train loss: 0.47077
Step #8300, epoch #2, avg. train loss: 0.46944
Step #8400, epoch #2, avg. train loss: 0.47356
Step #8500, epoch #2, avg. train loss: 0.46997
Step #8600, epoch #2, avg. train loss: 0.46793
Step #8700, epoch #2, avg. train loss: 0.47113
Step #8800, epoch #2, avg. train loss: 0.46718
Step #8900, epoch #2, avg. train loss: 0.46948
Recall @ (1, 10): 0.435583
Recall @ (2, 10): 0.597955
Recall @ (5, 10): 0.849693
Recall @ (10, 10): 1
Step #9000, epoch #2, avg. train loss: 0.47194
Step #9100, epoch #2, avg. train loss: 0.47065
Step #9200, epoch #2, avg. train loss: 0.47041
Step #9300, epoch #2, avg. train loss: 0.46941
Step #9400, epoch #2, avg. train loss: 0.46672
Step #9500, epoch #2, avg. train loss: 0.47063
Step #9600, epoch #2, avg. train loss: 0.46734
Step #9700, epoch #2, avg. train loss: 0.46982
Step #9800, epoch #2, avg. train loss: 0.47234
Step #9900, epoch #2, avg. train loss: 0.46509
Recall @ (1, 10): 0.435225
Recall @ (2, 10): 0.597699
Recall @ (5, 10): 0.849949
Recall @ (10, 10): 1
Step #10000, epoch #2, avg. train loss: 0.46734
Step #10100, epoch #2, avg. train loss: 0.46670
Step #10200, epoch #2, avg. train loss: 0.46985
Step #10300, epoch #2, avg. train loss: 0.47156
Step #10400, epoch #2, avg. train loss: 0.46670
Step #10500, epoch #2, avg. train loss: 0.46824
Step #10600, epoch #2, avg. train loss: 0.46843
Step #10700, epoch #2, avg. train loss: 0.47146
Step #10800, epoch #2, avg. train loss: 0.46333
Step #10900, epoch #2, avg. train loss: 0.46556
Recall @ (1, 10): 0.435072
Recall @ (2, 10): 0.598006
Recall @ (5, 10): 0.850307
Recall @ (10, 10): 1
Step #11000, epoch #2, avg. train loss: 0.47121
Step #11100, epoch #2, avg. train loss: 0.46767
Step #11200, epoch #2, avg. train loss: 0.46918
Step #11300, epoch #2, avg. train loss: 0.46629
Step #11400, epoch #2, avg. train loss: 0.46750
Step #11500, epoch #2, avg. train loss: 0.46980
Step #11600, epoch #2, avg. train loss: 0.46733
Step #11700, epoch #2, avg. train loss: 0.46630
Step #11800, epoch #3, avg. train loss: 0.47206
Step #11900, epoch #3, avg. train loss: 0.46094
Recall @ (1, 10): 0.435532
Recall @ (2, 10): 0.598364
Recall @ (5, 10): 0.850102
Recall @ (10, 10): 1
Step #12000, epoch #3, avg. train loss: 0.47030
Step #12100, epoch #3, avg. train loss: 0.47070
Step #12200, epoch #3, avg. train loss: 0.46293
Step #12300, epoch #3, avg. train loss: 0.46787
Step #12400, epoch #3, avg. train loss: 0.46619
Step #12500, epoch #3, avg. train loss: 0.46946
Step #12600, epoch #3, avg. train loss: 0.46511
Step #12700, epoch #3, avg. train loss: 0.46615
Step #12800, epoch #3, avg. train loss: 0.47180
Step #12900, epoch #3, avg. train loss: 0.46466
Recall @ (1, 10): 0.435276
Recall @ (2, 10): 0.598466
Recall @ (5, 10): 0.850204
Recall @ (10, 10): 1
Step #13000, epoch #3, avg. train loss: 0.46594
Step #13100, epoch #3, avg. train loss: 0.46723
Step #13200, epoch #3, avg. train loss: 0.47222
Step #13300, epoch #3, avg. train loss: 0.46808
Step #13400, epoch #3, avg. train loss: 0.46945
Step #13500, epoch #3, avg. train loss: 0.46822
Step #13600, epoch #3, avg. train loss: 0.47066
Step #13700, epoch #3, avg. train loss: 0.46745
Step #13800, epoch #3, avg. train loss: 0.46862
Step #13900, epoch #3, avg. train loss: 0.46537
Recall @ (1, 10): 0.435327
Recall @ (2, 10): 0.59862
Recall @ (5, 10): 0.850256
Recall @ (10, 10): 1
Step #14000, epoch #3, avg. train loss: 0.46841
Step #14100, epoch #3, avg. train loss: 0.46729
Step #14200, epoch #3, avg. train loss: 0.46637
Step #14300, epoch #3, avg. train loss: 0.46916
Step #14400, epoch #3, avg. train loss: 0.46427
Step #14500, epoch #3, avg. train loss: 0.46649
Step #14600, epoch #3, avg. train loss: 0.46347